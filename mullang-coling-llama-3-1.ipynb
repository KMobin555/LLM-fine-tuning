{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-13T12:53:32.897508Z",
     "iopub.status.busy": "2024-10-13T12:53:32.896848Z",
     "iopub.status.idle": "2024-10-13T12:55:00.212177Z",
     "shell.execute_reply": "2024-10-13T12:55:00.210938Z",
     "shell.execute_reply.started": "2024-10-13T12:53:32.897473Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U bitsandbytes\n",
    "%pip install -U transformers\n",
    "%pip install -U accelerate\n",
    "%pip install -U peft\n",
    "%pip install -U trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:00.214699Z",
     "iopub.status.busy": "2024-10-13T12:55:00.214353Z",
     "iopub.status.idle": "2024-10-13T12:55:02.790601Z",
     "shell.execute_reply": "2024-10-13T12:55:02.789649Z",
     "shell.execute_reply.started": "2024-10-13T12:55:00.214668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:02.792989Z",
     "iopub.status.busy": "2024-10-13T12:55:02.792140Z",
     "iopub.status.idle": "2024-10-13T12:55:23.594060Z",
     "shell.execute_reply": "2024-10-13T12:55:23.593204Z",
     "shell.execute_reply.started": "2024-10-13T12:55:02.792953Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 12:55:12.073094: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-13 12:55:12.073205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-13 12:55:12.199567: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:23.598226Z",
     "iopub.status.busy": "2024-10-13T12:55:23.596835Z",
     "iopub.status.idle": "2024-10-13T12:55:23.602057Z",
     "shell.execute_reply": "2024-10-13T12:55:23.601090Z",
     "shell.execute_reply.started": "2024-10-13T12:55:23.598193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv\",index_col = \"Unnamed: 0\") s\n",
    "# df.loc[:,'status'] = df.loc[:,'status'].str.replace('Bi-Polar','Bipolar')\n",
    "# df = df[(df.status != \"Personality disorder\") & (df.status != \"Stress\") & (df.status != \"Suicidal\")]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:23.603958Z",
     "iopub.status.busy": "2024-10-13T12:55:23.603509Z",
     "iopub.status.idle": "2024-10-13T12:55:33.826343Z",
     "shell.execute_reply": "2024-10-13T12:55:33.825488Z",
     "shell.execute_reply.started": "2024-10-13T12:55:23.603920Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sub_source</th>\n",
       "      <th>lang</th>\n",
       "      <th>model</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>c5f6649d-e63e-412a-9ee9-6c770a9741ce</td>\n",
       "      <td>mage</td>\n",
       "      <td>yelp</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Pizza was delivered in a timely fashion but it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285814</th>\n",
       "      <td>1ec924cf-0539-4f7b-9a4f-35746a5c6d35</td>\n",
       "      <td>mage</td>\n",
       "      <td>wp</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Mom, Jane and I want to know who you're going ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154227</th>\n",
       "      <td>e460e7ec-4ad0-407f-84be-ea04f3186c32</td>\n",
       "      <td>hc3</td>\n",
       "      <td>reddit_eli5</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Is there any species in particular you are ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242382</th>\n",
       "      <td>e3311384-e600-414c-83e3-870df2e945b3</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>The selection of features that are relevant fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186635</th>\n",
       "      <td>2e38e33e-360c-46ea-b41a-144f4163a63a</td>\n",
       "      <td>mage</td>\n",
       "      <td>wp</td>\n",
       "      <td>en</td>\n",
       "      <td>7B</td>\n",
       "      <td>1</td>\n",
       "      <td>ninja edit: I read \"paradise\" not \"parasite.\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>18411c12-fb33-4566-9403-e79a3d7bda2c</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>CHANGE-it NEWS</td>\n",
       "      <td>it</td>\n",
       "      <td>llama2-fine-tuned</td>\n",
       "      <td>1</td>\n",
       "      <td>Siate efficienti e meno occupati \". Sono quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>a177d884-5d67-493e-adca-02cbcfe73375</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>outfox</td>\n",
       "      <td>en</td>\n",
       "      <td>llama3-70b</td>\n",
       "      <td>1</td>\n",
       "      <td>The more the better ! Getting Advice from many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>7448626d-49b0-473d-81c2-938ad1db78a6</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>reddit</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know the text in the MS law specifical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>d087e101-0ad4-4c7c-90be-a7e9c9c07e8e</td>\n",
       "      <td>mage</td>\n",
       "      <td>xsum</td>\n",
       "      <td>en</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>Ian Coulter, formerly of Tughans, has been que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>8630a79f-5f82-4f34-9a63-21e8a3e1eb67</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>reddit</td>\n",
       "      <td>en</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>When it comes to transporting cargo, helicopte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288894 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id source      sub_source lang  \\\n",
       "14032   c5f6649d-e63e-412a-9ee9-6c770a9741ce   mage            yelp   en   \n",
       "285814  1ec924cf-0539-4f7b-9a4f-35746a5c6d35   mage              wp   en   \n",
       "154227  e460e7ec-4ad0-407f-84be-ea04f3186c32    hc3     reddit_eli5   en   \n",
       "242382  e3311384-e600-414c-83e3-870df2e945b3   m4gt           arxiv   en   \n",
       "186635  2e38e33e-360c-46ea-b41a-144f4163a63a   mage              wp   en   \n",
       "...                                      ...    ...             ...  ...   \n",
       "119879  18411c12-fb33-4566-9403-e79a3d7bda2c   m4gt  CHANGE-it NEWS   it   \n",
       "259178  a177d884-5d67-493e-adca-02cbcfe73375   m4gt          outfox   en   \n",
       "131932  7448626d-49b0-473d-81c2-938ad1db78a6   m4gt          reddit   en   \n",
       "146867  d087e101-0ad4-4c7c-90be-a7e9c9c07e8e   mage            xsum   en   \n",
       "121958  8630a79f-5f82-4f34-9a63-21e8a3e1eb67   m4gt          reddit   en   \n",
       "\n",
       "                    model  label  \\\n",
       "14032               human      0   \n",
       "285814              human      0   \n",
       "154227              human      0   \n",
       "242382              human      0   \n",
       "186635                 7B      1   \n",
       "...                   ...    ...   \n",
       "119879  llama2-fine-tuned      1   \n",
       "259178         llama3-70b      1   \n",
       "131932              human      0   \n",
       "146867              human      0   \n",
       "121958      gpt-3.5-turbo      1   \n",
       "\n",
       "                                                     text  \n",
       "14032   Pizza was delivered in a timely fashion but it...  \n",
       "285814  Mom, Jane and I want to know who you're going ...  \n",
       "154227  Is there any species in particular you are ref...  \n",
       "242382  The selection of features that are relevant fo...  \n",
       "186635  ninja edit: I read \"paradise\" not \"parasite.\" ...  \n",
       "...                                                   ...  \n",
       "119879  Siate efficienti e meno occupati \". Sono quest...  \n",
       "259178  The more the better ! Getting Advice from many...  \n",
       "131932  I don't know the text in the MS law specifical...  \n",
       "146867  Ian Coulter, formerly of Tughans, has been que...  \n",
       "121958  When it comes to transporting cargo, helicopte...  \n",
       "\n",
       "[288894 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df = pd.read_json('/kaggle/input/coling-25-task-1/multilingual_dev.jsonl', lines=True)\n",
    "percentage = 1 \n",
    "\n",
    "# Sample x percent of the DataFrame\n",
    "df = sampled_df.sample(frac=percentage, random_state=42)  # random_state for reproducibility\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:33.828062Z",
     "iopub.status.busy": "2024-10-13T12:55:33.827781Z",
     "iopub.status.idle": "2024-10-13T12:55:34.148125Z",
     "shell.execute_reply": "2024-10-13T12:55:34.147220Z",
     "shell.execute_reply.started": "2024-10-13T12:55:33.828037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/3410574939.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_df = df.groupby('lang').apply(lambda x: x.sample(min_size)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sub_source</th>\n",
       "      <th>lang</th>\n",
       "      <th>model</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fbaff8ff-f58e-4f8f-a2b1-354898940887</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>News/Wikipedia</td>\n",
       "      <td>ar</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>قال وزير الدفاع البريطاني، بن والاس، إن بريطان...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e6722859-fd0f-4409-93a3-8d3f8a814b53</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>News/Wikipedia</td>\n",
       "      <td>ar</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>حذرت إسرائيل حركتي المقاومة الإسلامية (حماس) و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61f490f4-5dc4-48d5-9105-d82e6e86f52d</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>News/Wikipedia</td>\n",
       "      <td>ar</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>أشار الدكتور بيرجر دولتس إلى أن اضطراب الشخصية...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98c3962d-08d2-48fe-bf82-6fce0ca1df4a</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>News/Wikipedia</td>\n",
       "      <td>ar</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>فريدة أحمد تسعى غالبية النساء إلى الحفاظ على ن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9a89e0f1-1998-430d-9fa1-ea80349cf36e</td>\n",
       "      <td>m4gt</td>\n",
       "      <td>News/Wikipedia</td>\n",
       "      <td>ar</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>أعلنت شركة أميركية ناشئة عن بيع روبوتها الجديد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>7e389a81-f356-42e1-95a9-616ca5482abb</td>\n",
       "      <td>hc3</td>\n",
       "      <td>law</td>\n",
       "      <td>zh</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>律师费诉前交，法院费用也是诉前。估计下来一万多。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>e95a6a83-7133-4c39-afc5-7df7afc50938</td>\n",
       "      <td>hc3</td>\n",
       "      <td>baike</td>\n",
       "      <td>zh</td>\n",
       "      <td>gpt-35</td>\n",
       "      <td>1</td>\n",
       "      <td>手机定位跟踪器是一种能够跟踪手机用户位置的技术。它通过使用手机的GPS、Wi-Fi或移动网络...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>14c31e57-33ba-491e-854e-17ad4647f47c</td>\n",
       "      <td>hc3</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>zh</td>\n",
       "      <td>gpt-35</td>\n",
       "      <td>1</td>\n",
       "      <td>学习识别各种车辆可能有一些挑战，但是有一些技巧可以帮助你更容易地区分不同的车型。 \\n1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>0a6c1e66-e939-43b6-9dca-9186de29650e</td>\n",
       "      <td>hc3</td>\n",
       "      <td>medicine</td>\n",
       "      <td>zh</td>\n",
       "      <td>gpt-35</td>\n",
       "      <td>1</td>\n",
       "      <td>羊角风是一种慢性传染病，其主要症状是肝脏、脾脏受到损害，导致肝功能异常。羊角风患者应避免食用...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>83b0bb5d-62fd-42d9-81da-db3202589283</td>\n",
       "      <td>hc3</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>zh</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>2015年7月 我生日 在家乡。正和蠢萌处于你侬我侬的热恋期。12年生日一个人睡一天。13年...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id source      sub_source lang  \\\n",
       "0     fbaff8ff-f58e-4f8f-a2b1-354898940887   m4gt  News/Wikipedia   ar   \n",
       "1     e6722859-fd0f-4409-93a3-8d3f8a814b53   m4gt  News/Wikipedia   ar   \n",
       "2     61f490f4-5dc4-48d5-9105-d82e6e86f52d   m4gt  News/Wikipedia   ar   \n",
       "3     98c3962d-08d2-48fe-bf82-6fce0ca1df4a   m4gt  News/Wikipedia   ar   \n",
       "4     9a89e0f1-1998-430d-9fa1-ea80349cf36e   m4gt  News/Wikipedia   ar   \n",
       "...                                    ...    ...             ...  ...   \n",
       "5395  7e389a81-f356-42e1-95a9-616ca5482abb    hc3             law   zh   \n",
       "5396  e95a6a83-7133-4c39-afc5-7df7afc50938    hc3           baike   zh   \n",
       "5397  14c31e57-33ba-491e-854e-17ad4647f47c    hc3         open_qa   zh   \n",
       "5398  0a6c1e66-e939-43b6-9dca-9186de29650e    hc3        medicine   zh   \n",
       "5399  83b0bb5d-62fd-42d9-81da-db3202589283    hc3         open_qa   zh   \n",
       "\n",
       "              model  label                                               text  \n",
       "0     gpt-3.5-turbo      1  قال وزير الدفاع البريطاني، بن والاس، إن بريطان...  \n",
       "1     gpt-3.5-turbo      1  حذرت إسرائيل حركتي المقاومة الإسلامية (حماس) و...  \n",
       "2     gpt-3.5-turbo      1  أشار الدكتور بيرجر دولتس إلى أن اضطراب الشخصية...  \n",
       "3     gpt-3.5-turbo      1  فريدة أحمد تسعى غالبية النساء إلى الحفاظ على ن...  \n",
       "4     gpt-3.5-turbo      1  أعلنت شركة أميركية ناشئة عن بيع روبوتها الجديد...  \n",
       "...             ...    ...                                                ...  \n",
       "5395          human      0                           律师费诉前交，法院费用也是诉前。估计下来一万多。  \n",
       "5396         gpt-35      1  手机定位跟踪器是一种能够跟踪手机用户位置的技术。它通过使用手机的GPS、Wi-Fi或移动网络...  \n",
       "5397         gpt-35      1  学习识别各种车辆可能有一些挑战，但是有一些技巧可以帮助你更容易地区分不同的车型。 \\n1. ...  \n",
       "5398         gpt-35      1  羊角风是一种慢性传染病，其主要症状是肝脏、脾脏受到损害，导致肝功能异常。羊角风患者应避免食用...  \n",
       "5399          human      0  2015年7月 我生日 在家乡。正和蠢萌处于你侬我侬的热恋期。12年生日一个人睡一天。13年...  \n",
       "\n",
       "[5400 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is the DataFrame you provided\n",
    "\n",
    "# Group by 'lang' and find the minimum group size\n",
    "min_size = df['lang'].value_counts().min()\n",
    "\n",
    "# Sample min_size rows for each language\n",
    "balanced_df = df.groupby('lang').apply(lambda x: x.sample(min_size)).reset_index(drop=True)\n",
    "df = balanced_df\n",
    "# Display the balanced DataFrame\n",
    "balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:34.150282Z",
     "iopub.status.busy": "2024-10-13T12:55:34.149604Z",
     "iopub.status.idle": "2024-10-13T12:55:34.160301Z",
     "shell.execute_reply": "2024-10-13T12:55:34.159194Z",
     "shell.execute_reply.started": "2024-10-13T12:55:34.150241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang\n",
       "ar    600\n",
       "bg    600\n",
       "de    600\n",
       "en    600\n",
       "id    600\n",
       "it    600\n",
       "ru    600\n",
       "ur    600\n",
       "zh    600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:34.161801Z",
     "iopub.status.busy": "2024-10-13T12:55:34.161526Z",
     "iopub.status.idle": "2024-10-13T12:55:34.179973Z",
     "shell.execute_reply": "2024-10-13T12:55:34.178934Z",
     "shell.execute_reply.started": "2024-10-13T12:55:34.161770Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/1625676964.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'text': 'statement', 'label': 'status'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قال وزير الدفاع البريطاني، بن والاس، إن بريطان...</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>حذرت إسرائيل حركتي المقاومة الإسلامية (حماس) و...</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>أشار الدكتور بيرجر دولتس إلى أن اضطراب الشخصية...</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>فريدة أحمد تسعى غالبية النساء إلى الحفاظ على ن...</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>أعلنت شركة أميركية ناشئة عن بيع روبوتها الجديد...</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>律师费诉前交，法院费用也是诉前。估计下来一万多。</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>手机定位跟踪器是一种能够跟踪手机用户位置的技术。它通过使用手机的GPS、Wi-Fi或移动网络...</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>学习识别各种车辆可能有一些挑战，但是有一些技巧可以帮助你更容易地区分不同的车型。 \\n1. ...</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>羊角风是一种慢性传染病，其主要症状是肝脏、脾脏受到损害，导致肝功能异常。羊角风患者应避免食用...</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>2015年7月 我生日 在家乡。正和蠢萌处于你侬我侬的热恋期。12年生日一个人睡一天。13年...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              statement   status\n",
       "0     قال وزير الدفاع البريطاني، بن والاس، إن بريطان...  machine\n",
       "1     حذرت إسرائيل حركتي المقاومة الإسلامية (حماس) و...  machine\n",
       "2     أشار الدكتور بيرجر دولتس إلى أن اضطراب الشخصية...  machine\n",
       "3     فريدة أحمد تسعى غالبية النساء إلى الحفاظ على ن...  machine\n",
       "4     أعلنت شركة أميركية ناشئة عن بيع روبوتها الجديد...  machine\n",
       "...                                                 ...      ...\n",
       "5395                           律师费诉前交，法院费用也是诉前。估计下来一万多。    human\n",
       "5396  手机定位跟踪器是一种能够跟踪手机用户位置的技术。它通过使用手机的GPS、Wi-Fi或移动网络...  machine\n",
       "5397  学习识别各种车辆可能有一些挑战，但是有一些技巧可以帮助你更容易地区分不同的车型。 \\n1. ...  machine\n",
       "5398  羊角风是一种慢性传染病，其主要症状是肝脏、脾脏受到损害，导致肝功能异常。羊角风患者应避免食用...  machine\n",
       "5399  2015年7月 我生日 在家乡。正和蠢萌处于你侬我侬的热恋期。12年生日一个人睡一天。13年...    human\n",
       "\n",
       "[5400 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to convert labels\n",
    "def convert_label(label):\n",
    "    return \"human\" if label == 0 else \"machine\"\n",
    "\n",
    "# Apply the conversion function to the 'label' column\n",
    "df['label'] = df['label'].apply(convert_label)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df = df[['text','label']]\n",
    "df.rename(columns={'text': 'statement', 'label': 'status'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:34.181573Z",
     "iopub.status.busy": "2024-10-13T12:55:34.181240Z",
     "iopub.status.idle": "2024-10-13T12:55:34.279143Z",
     "shell.execute_reply": "2024-10-13T12:55:34.278228Z",
     "shell.execute_reply.started": "2024-10-13T12:55:34.181544Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/4278169162.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\n",
      "/tmp/ipykernel_34/4278169162.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the DataFrame and select only 3000 rows\n",
    "df = df.sample(frac=1, random_state=85).reset_index(drop=True)\n",
    "\n",
    "# Split the DataFrame\n",
    "train_size = 0.8\n",
    "eval_size = 0.1\n",
    "\n",
    "# Calculate sizes\n",
    "train_end = int(train_size * len(df))\n",
    "eval_end = train_end + int(eval_size * len(df))\n",
    "\n",
    "# Split the data\n",
    "X_train = df[:train_end]\n",
    "X_eval = df[train_end:eval_end]\n",
    "X_test = df[eval_end:]\n",
    "\n",
    "\n",
    "System_message= \"You are an advanced AI model specialized in detecting whether a given text is machine-generated or human-written. Your expertise allows you to analyze texts in various languages with accuracy.\"\n",
    "\n",
    "# Define the prompt generation functions\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "    {System_message}\n",
    "    Please classify the following text and provide your answer as either \"machine generated\" or \"human written\".\n",
    "\n",
    "    Text: {data_point[\"statement\"]}\n",
    "    label: {data_point[\"status\"]}\"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "    {System_message}\n",
    "    Please classify the following text and provide your answer as either \"machine generated\" or \"human written\".\n",
    "\n",
    "    Text: {data_point[\"statement\"]}\n",
    "    label: \"\"\".strip()\n",
    "\n",
    "# Generate prompts for training and evaluation data\n",
    "X_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\n",
    "X_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)\n",
    "\n",
    "X_test = X_test.sample(frac=0.3, random_state=42)  # random_state for reproducibility\n",
    "\n",
    "# Generate test prompts and extract true labels\n",
    "y_true = X_test.loc[:,'status']\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:34.283914Z",
     "iopub.status.busy": "2024-10-13T12:55:34.283620Z",
     "iopub.status.idle": "2024-10-13T12:55:34.292948Z",
     "shell.execute_reply": "2024-10-13T12:55:34.291758Z",
     "shell.execute_reply.started": "2024-10-13T12:55:34.283889Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(status\n",
       " machine    2809\n",
       " human      1511\n",
       " Name: count, dtype: int64,\n",
       " status\n",
       " machine    335\n",
       " human      205\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.status.value_counts(),X_eval.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:34.294580Z",
     "iopub.status.busy": "2024-10-13T12:55:34.294273Z",
     "iopub.status.idle": "2024-10-13T12:55:34.306226Z",
     "shell.execute_reply": "2024-10-13T12:55:34.305193Z",
     "shell.execute_reply.started": "2024-10-13T12:55:34.294557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "machine    105\n",
       "human       57\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:34.307874Z",
     "iopub.status.busy": "2024-10-13T12:55:34.307510Z",
     "iopub.status.idle": "2024-10-13T12:55:34.397903Z",
     "shell.execute_reply": "2024-10-13T12:55:34.396828Z",
     "shell.execute_reply.started": "2024-10-13T12:55:34.307844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to datasets\n",
    "train_data = Dataset.from_pandas(X_train[[\"text\"]])\n",
    "eval_data = Dataset.from_pandas(X_eval[[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:34.399493Z",
     "iopub.status.busy": "2024-10-13T12:55:34.399107Z",
     "iopub.status.idle": "2024-10-13T12:55:34.434496Z",
     "shell.execute_reply": "2024-10-13T12:55:34.433413Z",
     "shell.execute_reply.started": "2024-10-13T12:55:34.399461Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an advanced AI model specialized in detecting whether a given text is machine-generated or human-written. Your expertise allows you to analyze texts in various languages with accuracy.\\n\\n    Please classify the following text and provide your answer as either \"machine generated\" or \"human written\".\\n\\n    Text: организации из числа юридических лиц (за исключением органа местного самоуправления и муниципального учреждения муниципальных образований автономного округа, государственного учреждения автономного округа, религиозной и общественной организации), отнесенные к крупным предприятиям, к средним предприятиям в соответствии со статьей 4 Федерального закона от 24 июля 2007 года № 209-ФЗ «О развитии малого и среднего предпринимательства в Российской Федерации», работники которых находятся под риском увольнения (простой, введение режима неполного рабочего времени, предоставление отпусков без сохранения заработной платы по инициативе работодателей, проведение мероприятий по высвобождению работников);\\n    label: human'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:55:34.436089Z",
     "iopub.status.busy": "2024-10-13T12:55:34.435719Z",
     "iopub.status.idle": "2024-10-13T12:57:48.107769Z",
     "shell.execute_reply": "2024-10-13T12:57:48.106980Z",
     "shell.execute_reply.started": "2024-10-13T12:55:34.436057Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130a1253844a4b268406fe4cfae44917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"/kaggle/input/llama-3.1/transformers/8b-instruct/1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"float16\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:57:48.109263Z",
     "iopub.status.busy": "2024-10-13T12:57:48.108951Z",
     "iopub.status.idle": "2024-10-13T12:57:48.799954Z",
     "shell.execute_reply": "2024-10-13T12:57:48.799115Z",
     "shell.execute_reply.started": "2024-10-13T12:57:48.109237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evalution before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:57:48.801996Z",
     "iopub.status.busy": "2024-10-13T12:57:48.801287Z",
     "iopub.status.idle": "2024-10-13T12:57:48.809564Z",
     "shell.execute_reply": "2024-10-13T12:57:48.808603Z",
     "shell.execute_reply.started": "2024-10-13T12:57:48.801956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    categories = [\"human\", \"machine\"]\n",
    "    \n",
    "    for i in tqdm(range(len(test))):\n",
    "        prompt = test.iloc[i][\"text\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        max_new_tokens=20, \n",
    "                        temperature=0.4)\n",
    "        \n",
    "        result = pipe(prompt)\n",
    "#         print(result)\n",
    "        answer = result[0]['generated_text'].split(\"label:\")[-1].strip()\n",
    "        \n",
    "        # Determine the predicted category\n",
    "        for category in categories:\n",
    "            if category.lower() in answer.lower():\n",
    "                y_pred.append(category)\n",
    "                break\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:57:48.811225Z",
     "iopub.status.busy": "2024-10-13T12:57:48.810874Z",
     "iopub.status.idle": "2024-10-13T12:57:48.823189Z",
     "shell.execute_reply": "2024-10-13T12:57:48.822385Z",
     "shell.execute_reply.started": "2024-10-13T12:57:48.811193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = [\"human\", \"machine\"]\n",
    "    mapping = {label: idx for idx, label in enumerate(labels)}\n",
    "    \n",
    "    def map_func(x):\n",
    "        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n",
    "    \n",
    "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "    y_pred_mapped = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true_mapped)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n",
    "        label_y_true = [y_true_mapped[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n",
    "        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T12:57:48.824781Z",
     "iopub.status.busy": "2024-10-13T12:57:48.824428Z",
     "iopub.status.idle": "2024-10-13T13:05:21.313523Z",
     "shell.execute_reply": "2024-10-13T13:05:21.312310Z",
     "shell.execute_reply.started": "2024-10-13T12:57:48.824750Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/162 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|██████████| 162/162 [07:32<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine', 'human', 'machine', 'machine', 'machine', 'human', 'machine', 'human', 'machine', 'machine', 'human', 'human', 'machine', 'machine', 'machine', 'human', 'none', 'machine', 'machine', 'machine', 'machine', 'machine', 'human', 'machine', 'human', 'machine', 'none', 'machine', 'machine', 'machine', 'machine', 'human', 'machine', 'human', 'machine', 'machine', 'machine', 'machine', 'human', 'none', 'machine', 'machine', 'machine', 'human', 'machine', 'machine', 'machine', 'human', 'machine', 'human', 'machine', 'machine', 'machine', 'machine', 'machine', 'machine', 'human', 'human', 'machine', 'machine', 'human', 'none', 'human', 'machine', 'human', 'machine', 'human', 'machine', 'machine', 'machine', 'machine', 'machine', 'human', 'machine', 'machine', 'machine', 'machine', 'machine', 'machine', 'human', 'machine', 'machine', 'machine', 'machine', 'machine', 'machine', 'machine', 'machine', 'human', 'machine', 'machine', 'machine', 'machine', 'human', 'machine', 'machine', 'machine', 'machine', 'human', 'human', 'human', 'none', 'machine', 'machine', 'human', 'machine', 'none', 'human', 'machine', 'human', 'human', 'machine', 'machine', 'none', 'machine', 'machine', 'machine', 'none', 'machine', 'machine', 'machine', 'machine', 'machine', 'human', 'machine', 'none', 'human', 'human', 'machine', 'machine', 'machine', 'machine', 'machine', 'none', 'human', 'machine', 'machine', 'machine', 'none', 'machine', 'human', 'human', 'machine', 'machine', 'machine', 'human', 'machine', 'human', 'machine', 'human', 'human', 'machine', 'none', 'machine', 'machine', 'machine', 'none', 'none', 'machine', 'machine', 'human', 'human']\n",
      "Accuracy: 0.549\n",
      "Accuracy for label human: 0.316\n",
      "Accuracy for label machine: 0.676\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       human       0.42      0.32      0.36        57\n",
      "     machine       0.68      0.68      0.68       105\n",
      "\n",
      "   micro avg       0.60      0.55      0.57       162\n",
      "   macro avg       0.55      0.50      0.52       162\n",
      "weighted avg       0.59      0.55      0.56       162\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18 34]\n",
      " [25 71]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = predict(X_test, model, tokenizer)\n",
    "print(y_pred)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the linear modules names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T13:05:21.315072Z",
     "iopub.status.busy": "2024-10-13T13:05:21.314683Z",
     "iopub.status.idle": "2024-10-13T13:05:21.323405Z",
     "shell.execute_reply": "2024-10-13T13:05:21.322502Z",
     "shell.execute_reply.started": "2024-10-13T13:05:21.315040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T13:05:21.324779Z",
     "iopub.status.busy": "2024-10-13T13:05:21.324456Z",
     "iopub.status.idle": "2024-10-13T13:05:21.339098Z",
     "shell.execute_reply": "2024-10-13T13:05:21.338019Z",
     "shell.execute_reply.started": "2024-10-13T13:05:21.324751Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gate_proj', 'down_proj', 'v_proj', 'k_proj', 'q_proj', 'up_proj', 'o_proj']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = find_all_linear_names(model)\n",
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T13:05:21.341044Z",
     "iopub.status.busy": "2024-10-13T13:05:21.340719Z",
     "iopub.status.idle": "2024-10-13T13:05:27.998939Z",
     "shell.execute_reply": "2024-10-13T13:05:27.997898Z",
     "shell.execute_reply.started": "2024-10-13T13:05:21.341017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:327: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2639f11a059841fbad4f65076a54f448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f40e3dff8ad49359435fc4dedd7a322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/540 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir=\"llama-3.1-fine-tuned-model\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0,\n",
    "    r=32,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules,\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=1,                       # number of training epochs\n",
    "    per_device_train_batch_size=1,            # batch size per device during training\n",
    "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,                         \n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    save_total_limit=2,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    eval_strategy=\"steps\",                    # save checkpoint every epoch\n",
    "    eval_steps = 0.1\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "    \"add_special_tokens\": False,\n",
    "    \"append_concat_token\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-13T13:05:28.001171Z",
     "iopub.status.busy": "2024-10-13T13:05:28.000342Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  8/540 02:41 < 3:58:45, 0.04 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training started\")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training ended\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define your variables\n",
    "dir_to_zip = output_dir\n",
    "\n",
    "# Define the name of the output zip file\n",
    "last_word = model.split('/')[-1]\n",
    "output_zip = f\"mullin_{output_dir}.zip\"\n",
    "\n",
    "shutil.make_archive(output_zip.replace('.zip', ''), 'zip', dir_to_zip)\n",
    "print(f\"Zipped contents of {dir_to_zip} into {output_zip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model after fine-tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_json('/kaggle/input/coling-25-task-1/multilingual_devtest_text_id_only.jsonl', lines=True)\n",
    "sub_df\n",
    "\n",
    "def generate_test_prompt_sub(data_point):\n",
    "    return f\"\"\"\n",
    "    {System_message}\n",
    "    Please classify the following text and provide your answer as either \"machine generated\" or \"human written\".\n",
    "\n",
    "    Text: {data_point[\"text\"]}\n",
    "    label: \"\"\".strip()\n",
    "\n",
    "sub_df['text'] = sub_df.apply(generate_test_prompt_sub, axis=1)\n",
    "sub_df = sub_df.sample(frac=0.01, random_state=42)  # random_state for reproducibility\n",
    "\n",
    "print(len(sub_df))\n",
    "\n",
    "predictions = predict(sub_df, model, tokenizer)\n",
    "\n",
    "print(\"prediction ended\")\n",
    "\n",
    "prediction_file_taska = 'task_b_llm_after_training.jsonl' \n",
    "predictions_df = pd.DataFrame({'id': sub_df.id, 'label': predictions})\n",
    "predictions_df.to_json(prediction_file_taska, lines=True, orient='records')\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5338273,
     "sourceId": 8870083,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5700992,
     "sourceId": 9393827,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 81881,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
